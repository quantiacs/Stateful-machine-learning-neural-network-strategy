{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "565d072f-1457-4e70-988c-67809d76d325",
   "metadata": {},
   "source": [
    "# Stateful  Machine learning  strategy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f3613b-fad4-4221-b34f-c420fac1f075",
   "metadata": {},
   "source": [
    "# Strategy Logic\n",
    "This strategy aims to predict the price movements of the top low-volatility stocks in the S&P 500 index using a fully connected neural network model.\n",
    "The model takes as input a set of technical indicators, and it outputs predictions for price direction over a one-day interval. The primary goal is to\n",
    "determine which assets are likely to rise, and adjust portfolio weights accordingly.\n",
    "\n",
    "\n",
    "Key Elements\n",
    "- Input Features: The strategy uses several technical indicators such as ATR (Average True Range) devided by close price and multiple RSI (Relative Strength Index) normalized values with different time frames (7, 20, 60, 150) to capture different market conditions.\n",
    "- Neural Network: A fully connected neural network with two hidden layers is used for predictions. The network outputs the likelihood of each asset's price rising.\n",
    "- Target Classes: The strategy classifies future price movement into two categories: up or down, based on the closing price.\n",
    "- Low-Volatility Asset Selection: The top 15 least volatile assets are selected daily to reduce risk and focus on stable assets.    \n",
    "\n",
    "Model Architecture\n",
    "The neural network model is defined with the following structure:\n",
    "\n",
    "- Input Layer: Receives the features for the selected assets.\n",
    "- Hidden Layers: Two layers with ReLU activation are used to capture complex relationships in the data.\n",
    "- Output Layer: Produces probabilities for each of the top 15 assets, indicating the likelihood of a price increase.\n",
    "\n",
    "Feature Engineering\n",
    "The following features are extracted from the asset price data:\n",
    "\n",
    "- ATR Percentage: Measures volatility as a percentage of the closing price.\n",
    "- Normalized RSI: RSI values for different periods (7, 20, 60, and 150) are normalized to better capture overbought or oversold conditions.\n",
    "- Candlestick Patterns: Simple candlestick feature based on the open and close prices\n",
    "\n",
    "Training and Prediction\n",
    "Training: The model is trained on historical data for the top 15 low-volatility assets, retrain interval is 90 days. The binary cross-entropy loss\n",
    "function is used to train the network over 100 epochs. Adam optimizer is applied for parameter updates.\n",
    "\n",
    "Prediction: Once trained, the model predicts whether the price will rise or fall for each of the top assets. Based on the predictions,\n",
    "the weights of the portfolio are updated up to 0.1 which is maximum, according to probabilities of rising, if that probabiliti is higher than 70%.\n",
    "\n",
    "\n",
    "Three types of exit conditions are used: take-profit, stop-loss and maximum holding period. The exits are defined as follows:\n",
    "\n",
    "- Take-Profit Exit: The strategy includes a take-profit mechanism, which triggers when the price of an asset has increased by a certain percentage from its open price. In this implementation, the take-profit level is set to 23% of the open price. This ensures that when the close price reaches a 23% gain, the position is exited to secure profits.\n",
    "\n",
    "- Stop-Loss Exit: To protect against significant losses, a stop-loss condition is applied. This stop-loss is set to 5% of the open price. If the asset's close price falls by 5% from the entry open price, the position is closed, preventing further losses beyond that threshold.\n",
    "\n",
    "- Maximum Holding Period: The strategy also enforces a maximum holding period of 217 days. This ensures that positions are not held indefinitely. If a position remains open for 217 days, it is automatically closed, even if the price has not triggered either the take-profit or stop-loss conditions.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5475839-3204-4b0c-84d8-49b6dcbe9cd2",
   "metadata": {},
   "source": [
    "**Important!** It is necessary  to run the ./init.py file once to install the PyTorch dependency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c68bed-d209-4fe0-9d80-4d60c1ccd2ec",
   "metadata": {},
   "source": [
    "!pip install torch==2.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12690248-5710-462d-ade5-204d720cd01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run the last iteration...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |#                                              | 15870 Elapsed Time: 0:00:00\n",
      "| |    #                                        | 2916631 Elapsed Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetched chunk 1/1 25s\n",
      "Data loaded 26s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikola.zezelj\\AppData\\Local\\anaconda3\\envs\\qntdev\\lib\\site-packages\\numpy\\core\\numeric.py:407: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in cast\n",
      "\n",
      "NOTICE: The environment variable OUT_STATE_PATH was not specified. The default value is 'state.out.pickle.gz'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| | #                                            | 380703 Elapsed Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetched chunk 1/1 6s\n",
      "Data loaded 6s\n",
      "Output cleaning...\n",
      "fix uniq\n",
      "ffill if the current price is None...\n",
      "Check liquidity...\n",
      "Ok.\n",
      "Check missed dates...\n",
      "Ok.\n",
      "Normalization...\n",
      "Output cleaning is complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NOTICE: The environment variable OUTPUT_PATH was not specified. The default value is 'fractions.nc.gz'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write output: fractions.nc.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NOTICE: The environment variable OUT_STATE_PATH was not specified. The default value is 'state.out.pickle.gz'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State saved.\n",
      "---\n",
      "Run First Iteration...\n",
      "fetched chunk 1/1 0s\n",
      "Data loaded 0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikola.zezelj\\AppData\\Local\\anaconda3\\envs\\qntdev\\lib\\site-packages\\numpy\\core\\numeric.py:407: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in cast\n",
      "\n",
      "NOTICE: The environment variable OUT_STATE_PATH was not specified. The default value is 'state.out.pickle.gz'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State saved.\n",
      "---\n",
      "Run all iterations...\n",
      "Load data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |#                                              | 15870 Elapsed Time: 0:00:00\n",
      "| |     #                                       | 3205187 Elapsed Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetched chunk 1/14 2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |     #                                       | 3197822 Elapsed Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetched chunk 2/14 4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |     #                                       | 3211074 Elapsed Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetched chunk 3/14 6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |     #                                       | 2990246 Elapsed Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetched chunk 4/14 8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |     #                                       | 3080319 Elapsed Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetched chunk 5/14 10s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |     #                                       | 3398392 Elapsed Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetched chunk 6/14 12s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |     #                                       | 3329688 Elapsed Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetched chunk 7/14 14s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |     #                                       | 3343294 Elapsed Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetched chunk 8/14 16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |     #                                       | 3410819 Elapsed Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetched chunk 9/14 18s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |     #                                       | 3385500 Elapsed Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetched chunk 10/14 20s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |     #                                       | 3407596 Elapsed Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetched chunk 11/14 22s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |     #                                       | 3710466 Elapsed Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetched chunk 12/14 24s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |     #                                       | 3567955 Elapsed Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetched chunk 13/14 26s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| | #                                            | 270023 Elapsed Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetched chunk 14/14 27s\n",
      "Data loaded 28s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |#                                              | 15870 Elapsed Time: 0:00:00\n",
      "| |     #                                       | 3292351 Elapsed Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetched chunk 1/12 2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |     #                                       | 3301412 Elapsed Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetched chunk 2/12 4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |     #                                       | 3281393 Elapsed Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetched chunk 3/12 6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |     #                                       | 3041546 Elapsed Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetched chunk 4/12 8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |     #                                       | 3373965 Elapsed Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetched chunk 5/12 10s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |     #                                       | 3390455 Elapsed Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetched chunk 6/12 12s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |      #                                      | 3367453 Elapsed Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetched chunk 7/12 14s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |     #                                       | 3443594 Elapsed Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetched chunk 8/12 16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |     #                                       | 3420108 Elapsed Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetched chunk 9/12 18s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |     #                                       | 3438606 Elapsed Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetched chunk 10/12 21s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |     #                                       | 3741459 Elapsed Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetched chunk 11/12 23s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |     #                                       | 3135262 Elapsed Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetched chunk 12/12 25s\n",
      "Data loaded 26s\n",
      "Backtest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikola.zezelj\\AppData\\Local\\anaconda3\\envs\\qntdev\\lib\\site-packages\\numpy\\core\\numeric.py:407: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in cast\n",
      "\n",
      "NOTICE: The environment variable OUT_STATE_PATH was not specified. The default value is 'state.out.pickle.gz'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% (4726 of 4727) |################### | Elapsed Time: 1:51:30 ETA:   0:00:01"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetched chunk 1/12 0s\n",
      "fetched chunk 2/12 0s\n",
      "fetched chunk 3/12 0s\n",
      "fetched chunk 4/12 0s\n",
      "fetched chunk 5/12 0s\n",
      "fetched chunk 6/12 0s\n",
      "fetched chunk 7/12 0s\n",
      "fetched chunk 8/12 1s\n",
      "fetched chunk 9/12 1s\n",
      "fetched chunk 10/12 1s\n",
      "fetched chunk 11/12 1s\n",
      "fetched chunk 12/12 1s\n",
      "Data loaded 1s\n",
      "Output cleaning...\n",
      "fix uniq\n",
      "ffill if the current price is None...\n",
      "Check liquidity...\n",
      "Ok.\n",
      "Check missed dates...\n",
      "Ok.\n",
      "Normalization...\n",
      "Output cleaning is complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NOTICE: The environment variable OUTPUT_PATH was not specified. The default value is 'fractions.nc.gz'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write output: fractions.nc.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NOTICE: The environment variable OUT_STATE_PATH was not specified. The default value is 'state.out.pickle.gz'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State saved.\n",
      "---\n",
      "Analyze results...\n",
      "Check...\n",
      "Check liquidity...\n",
      "Ok.\n",
      "Check missed dates...\n",
      "Ok.\n",
      "Check the sharpe ratio...\n",
      "Period: 2006-01-01 - 2024-10-14\n",
      "Sharpe Ratio = 0.8501869146305707\n",
      "Ok.\n",
      "---\n",
      "Align...\n",
      "Calc global stats...\n",
      "---\n",
      "Calc stats per asset...\n",
      "Build plots...\n",
      "---\n",
      "Select the asset (or leave blank to display the overall stats):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33c5af339df849559c1ce5305b494808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Combobox(value='', description='asset', options=('', 'NAS:AAL', 'NAS:AAPL', 'NAS:ABNB', â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (4727 of 4727) |####################| Elapsed Time: 1:51:45 Time:  1:51:45\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import qnt.data as qndata  \n",
    "import qnt.output as qnout   \n",
    "import qnt.backtester as qnbt \n",
    "import qnt.stats as qnstats \n",
    "import qnt.graph as qngraph \n",
    "import qnt.ta as qnta   \n",
    "import qnt.xr_talib as xr_talib   \n",
    "import qnt.state as qnstate \n",
    "import qnt.exits as qnte\n",
    "import qnt.filter as qnfilter\n",
    "import qnt.exposure as qnexp\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "global_lookback_period = 450\n",
    "global_train_period = 250\n",
    "global_count_features_for_ml = 6\n",
    "prediction_interval = 1 \n",
    "global_top_assets=15\n",
    "\n",
    "\n",
    "# Define the neural network model\n",
    "class FullyConnectedNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(FullyConnectedNN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "                    nn.Linear(input_dim, 128),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(128, 64),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(64, global_top_assets),  \n",
    "                    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Set seed for reproducibility\n",
    "def set_seed(seed_value=42):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    set_seed(42)\n",
    "    input_dim = global_top_assets * global_count_features_for_ml\n",
    "    model = FullyConnectedNN(input_dim)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_features(data):\n",
    "    close = data.sel(field=\"close\").ffill('time').bfill('time').fillna(1)\n",
    "    high = data.sel(field=\"high\").ffill('time').bfill('time').fillna(1)\n",
    "    low = data.sel(field=\"low\").ffill('time').bfill('time').fillna(1)\n",
    "    open = data.sel(field=\"open\").ffill('time').bfill('time').fillna(1)\n",
    "    previous_close = qnta.shift(close, 1)\n",
    "\n",
    "    atr = qnta.atr(high, low, close, 14).ffill('time').bfill('time').fillna(0)\n",
    "    atr_perc = (atr / close).ffill('time').bfill('time').fillna(0)\n",
    "\n",
    "    rsi = qnta.rsi(close, 7).ffill('time').bfill('time').fillna(0)\n",
    "    normalized_rsi7 = ((rsi - 50) * (7 ** 0.5) / 65).ffill('time').bfill('time').fillna(0)\n",
    "\n",
    "\n",
    "    rsi20 = qnta.rsi(close, 20).ffill('time').bfill('time').fillna(0)\n",
    "    normalized_rsi20 = ((rsi20 - 50) * (20 ** 0.5) / 65).ffill('time').bfill('time').fillna(0)\n",
    "    \n",
    "    rsi60 = qnta.rsi(close, 60).ffill('time').bfill('time').fillna(0)\n",
    "    normalized_rsi60 = ((rsi60 - 50) * (60 ** 0.5) / 65).ffill('time').bfill('time').fillna(0)\n",
    "\n",
    "    rsi150 = qnta.rsi(close, 150).ffill('time').bfill('time').fillna(0)\n",
    "    normalized_rsi150 = ((rsi150 - 50) * (150 ** 0.5) / 65).ffill('time').bfill('time').fillna(0)\n",
    "\n",
    "    candle = ((close - open) / (close * 2 * np.maximum(atr, 0.01))).ffill('time').bfill('time').fillna(0)\n",
    "\n",
    "    features = xr.concat([ normalized_rsi7, normalized_rsi20, candle,normalized_rsi60,normalized_rsi150, atr_perc], \"feature\")\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "\n",
    "def get_target_classes(data):\n",
    "    close_price = data.sel(field='close')\n",
    "    high_price = data.sel(field='high')\n",
    "    low_price = data.sel(field='low')\n",
    "    \n",
    "    atr = qnta.atr(high_price, low_price, close_price, 14).ffill('time').bfill('time').fillna(0)\n",
    "    future_price = qnta.shift(close_price, -1)\n",
    "    threshold = close_price \n",
    "    \n",
    "    class_positive = 1\n",
    "    class_negative = 0\n",
    "    \n",
    "    target_price_up = xr.where(future_price > threshold, class_positive, class_negative)\n",
    "    \n",
    "    return target_price_up\n",
    "\n",
    "\n",
    "def get_top_low_volatility_stocks(data):\n",
    "    is_liquid = data.sel(field=\"is_liquid\")\n",
    "\n",
    "   \n",
    "    last_assets = is_liquid[-1]\n",
    "    is_liquid_asset_list = last_assets.where(last_assets > 0, drop=True).asset.values\n",
    "\n",
    "   \n",
    "    data_liquid = data.sel(asset=is_liquid_asset_list)\n",
    "\n",
    "   \n",
    "    rolling_window = min(global_lookback_period, len(data_liquid.time) - 1)\n",
    "\n",
    "   \n",
    "    low_volatility = qnfilter.filter_volatility(\n",
    "        data=data_liquid,\n",
    "        rolling_window=rolling_window,\n",
    "        top_assets=global_top_assets,\n",
    "        metric=\"std\",\n",
    "        ascending=True\n",
    "    )\n",
    "\n",
    "   \n",
    "    last_asset = low_volatility[-1]\n",
    "    top_assets_indices = last_asset.where(last_asset > 0, drop=True).asset.values\n",
    "\n",
    "   \n",
    "    data_all_dates = data.sel(asset=top_assets_indices)\n",
    "\n",
    "    return data_all_dates\n",
    "\n",
    "\n",
    "# Load data\n",
    "def load_data(period):\n",
    "    data = qndata.stocks.load_spx_data(tail=period)\n",
    "    return data\n",
    "\n",
    "# Train the model\n",
    "def train_model(data):\n",
    "    \n",
    "    data_train = get_top_low_volatility_stocks(data)\n",
    "\n",
    "    features_all = get_features(data_train)\n",
    "    target_all = get_target_classes(data_train)\n",
    "\n",
    "   \n",
    "    target_all, features_all = xr.align(target_all, features_all, join='inner')\n",
    "    feature_data = features_all.transpose('time', 'feature', 'asset').values.reshape(-1, global_top_assets * global_count_features_for_ml)\n",
    "    target_data = target_all.transpose('time', 'asset').values\n",
    "\n",
    "   \n",
    "    feature_data = torch.tensor(feature_data, dtype=torch.float32)\n",
    "    target_data = torch.tensor(target_data, dtype=torch.float32)\n",
    "\n",
    "    \n",
    "\n",
    "   \n",
    "    model = get_model()\n",
    "   \n",
    "    criterion = nn.BCELoss()\n",
    "    optimiser = optim.Adam(model.parameters(), lr=0.002)\n",
    "    \n",
    "    epochs = 100\n",
    "\n",
    "   \n",
    "    for epoch in range(epochs):\n",
    "        optimiser.zero_grad()\n",
    "        out = model(feature_data)\n",
    "        loss = criterion(out, target_data)\n",
    "       # print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item()}\")\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        \n",
    "    return model\n",
    "\n",
    "def predict(model, data, state):\n",
    "    last_data_time = data.time.values[-1]\n",
    "    if state is None or state['weights'].time.values[-1] > last_data_time:\n",
    "        state = {\n",
    "            \"weights\": xr.zeros_like(data.sel(field='close')),\n",
    "            \"holding_time\": xr.zeros_like(data.isel(time=-1).asset, dtype=int),\n",
    "            \"model\": None,\n",
    "            \"open_price\": xr.full_like(data.isel(time=-1).asset, np.nan, dtype=int)\n",
    "           \n",
    "        }\n",
    "        qnstate.write(state)\n",
    "    \n",
    "\n",
    "   \n",
    "    weights_prev = state['weights']    \n",
    "    atr14 = qnta.atr(data.sel(field='high'), data.sel(field='low'), data.sel(field='close'), 14)\n",
    "    last_atr = atr14.isel(time=-1)\n",
    "   \n",
    "    data_top_assets = get_top_low_volatility_stocks(data)\n",
    "    last_time = data_top_assets.time.values[-1]\n",
    "    features_last_day = get_features(data_top_assets).sel(time=data_top_assets.time[-1])\n",
    "    \n",
    "    weights = xr.zeros_like(data.sel(field='close'))\n",
    "    weights_prev, weights = xr.align(weights_prev, weights, join='right')\n",
    "    \n",
    "    # First,rewrite previous  weights for all assets and dates\n",
    "    weights = xr.where(weights_prev > 0, weights_prev, weights)\n",
    "    # Rewrite previous day's  weights for last day\n",
    "    weights.loc[dict(time=last_time)] = weights_prev.shift(time=1).loc[dict(time=last_time)]\n",
    "    # Prepare the features for prediction\n",
    "    feature_data = features_last_day.transpose('feature', 'asset').values.reshape(1, -1)\n",
    "    feature_data = torch.tensor(feature_data, dtype=torch.float32)\n",
    "    \n",
    "    # Predict new weights using the model for the top low volatility assets\n",
    "    with torch.no_grad():\n",
    "        out = model(feature_data)\n",
    "    predictions = out.squeeze().numpy()\n",
    "   \n",
    "    \n",
    "    # Update the weights for the predicted top assets with the model's predictions\n",
    "    for idx, asset_name in enumerate(data_top_assets.asset.values):\n",
    "           if( predictions[idx] >0.7):\n",
    "             weights.loc[dict(asset=asset_name, time=last_time)] = predictions[idx]*0.1\n",
    "    \n",
    "    weights = weights * data.sel(field=\"is_liquid\")\n",
    "    \n",
    "    signal_dc = qnte.max_hold_long(weights, state, max_period=217)\n",
    "    open_price=qnte.update_open_price(data, weights, state)\n",
    "    tpLong=qnte.take_profit_long_percentage(data, weights, open_price, percent=23)\n",
    "    slLong=qnte.stop_loss_long_percentage(data, weights, open_price, percent=5)\n",
    "\n",
    "    weights = weights* tpLong* slLong*signal_dc\n",
    "    weights_sum = abs(weights).sum('asset')\n",
    "    weights = xr.where(weights_sum> 1, weights / weights_sum, weights)\n",
    "    state['weights'] = weights\n",
    "    state['model'] = model\n",
    "   \n",
    "\n",
    "\n",
    "    return  weights, state\n",
    " \n",
    "\n",
    "# Backtesting\n",
    "weights = qnbt.backtest_ml(\n",
    "    load_data=load_data,\n",
    "    train=train_model,\n",
    "    predict=predict,\n",
    "    train_period=global_train_period,\n",
    "    retrain_interval=90,\n",
    "    retrain_interval_after_submit=90,\n",
    "    predict_each_day=True,  \n",
    "    competition_type='stocks_s&p500',\n",
    "    lookback_period=global_lookback_period,\n",
    "    start_date='2006-01-01',\n",
    "    build_plots=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de78e4a5-824b-4490-a074-723823edb4ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
